
@inproceedings{skandarani_effectiveness_2020,
	title = {On the effectiveness of {GAN} generated cardiac {MRIs} for segmentation},
	copyright = {All rights reserved},
	url = {https://openreview.net/forum?id=f9Pl3Qj3_Q},
	abstract = {In this work, we propose a Variational Autoencoder (VAE) - Generative Adversarial Networks (GAN) model that can produce highly realistic MRI together with its pixel accurate groundtruth for the...},
	urldate = {2020-04-29},
	author = {Skandarani, Youssef and Painchaud, Nathan and Jodoin, Pierre-Marc and Lalande, Alain},
	month = jan,
	year = {2020},
	file = {Full Text PDF:/home/nathan/Zotero/storage/NXEL9ARQ/Skandarani et al. - 2020 - On the effectiveness of GAN generated cardiac MRIs.pdf:application/pdf;Snapshot:/home/nathan/Zotero/storage/6WKWKQYQ/forum.html:text/html},
}

@inproceedings{painchaud_cardiac_2019,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Cardiac {MRI} {Segmentation} with {Strong} {Anatomical} {Guarantees}},
	copyright = {All rights reserved},
	isbn = {978-3-030-32245-8},
	doi = {10.1007/978-3-030-32245-8_70},
	abstract = {Recent publications have shown that the segmentation accuracy of modern-day convolutional neural networks (CNN) applied on cardiac MRI can reach the inter-expert variability, a great achievement in this area of research. However, despite these successes, CNNs still produce anatomically inaccurate segmentations as they provide no guarantee on the anatomical plausibility of their outcome, even when using a shape prior. In this paper, we propose a cardiac MRI segmentation method which always produces anatomically plausible results. At the core of the method is an adversarial variational autoencoder (aVAE) whose latent space encodes a smooth manifold on which lies a large spectrum of valid cardiac shapes. This aVAE is used to automatically warp anatomically inaccurate cardiac shapes towards a close but correct shape. Our method can accommodate any cardiac segmentation method and convert its anatomically implausible results to plausible ones without affecting its overall geometric and clinical metrics. With our method, CNNs can now produce results that are both within the inter-expert variability and always anatomically plausible.},
	language = {en},
	booktitle = {Medical {Image} {Computing} and {Computer} {Assisted} {Intervention} – {MICCAI} 2019},
	author = {Painchaud, Nathan and Skandarani, Youssef and Judge, Thierry and Bernard, Olivier and Lalande, Alain and Jodoin, Pierre-Marc},
	year = {2019},
	keywords = {Cardiac MRI segmentation, CNN, Variational autoencoder},
	pages = {632--640},
	file = {Painchaud et al. - 2019 - Cardiac MRI Segmentation with Strong Anatomical Gu.pdf:/home/nathan/Zotero/storage/2DBP9VCG/Painchaud et al. - 2019 - Cardiac MRI Segmentation with Strong Anatomical Gu.pdf:application/pdf},
}

@article{painchaud_cardiac_2020,
	title = {Cardiac {Segmentation} {With} {Strong} {Anatomical} {Guarantees}},
	volume = {39},
	copyright = {All rights reserved},
	issn = {1558-254X},
	doi = {10.1109/TMI.2020.3003240},
	abstract = {Convolutional neural networks (CNN) have had unprecedented success in medical imaging and, in particular, in medical image segmentation. However, despite the fact that segmentation results are closer than ever to the inter-expert variability, CNNs are not immune to producing anatomically inaccurate segmentations, even when built upon a shape prior. In this paper, we present a framework for producing cardiac image segmentation maps that are guaranteed to respect pre-defined anatomical criteria, while remaining within the inter-expert variability. The idea behind our method is to use a well-trained CNN, have it process cardiac images, identify the anatomically implausible results and warp these results toward the closest anatomically valid cardiac shape. This warping procedure is carried out with a constrained variational autoencoder (cVAE) trained to learn a representation of valid cardiac shapes through a smooth, yet constrained, latent space. With this cVAE, we can project any implausible shape into the cardiac latent space and steer it toward the closest correct shape. We tested our framework on short-axis MRI as well as apical two and four-chamber view ultrasound images, two modalities for which cardiac shapes are drastically different. With our method, CNNs can now produce results that are both within the inter-expert variability and always anatomically plausible without having to rely on a shape prior.},
	number = {11},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Painchaud, Nathan and Skandarani, Youssef and Judge, Thierry and Bernard, Olivier and Lalande, Alain and Jodoin, Pierre-Marc},
	month = nov,
	year = {2020},
	keywords = {Image segmentation, CNN, Three-dimensional displays, Ultrasonic imaging, ultrasound, Shape, Magnetic resonance imaging, MRI, Neural networks, cardiac segmentation, variational autoencoder},
	pages = {3703--3713},
	file = {IEEE Xplore Abstract Record:/home/nathan/Zotero/storage/PDRSPL9Q/9119450.html:text/html;IEEE Xplore Full Text PDF:/home/nathan/Zotero/storage/VQ7P5VQZ/Painchaud et al. - 2020 - Cardiac Segmentation With Strong Anatomical Guaran.pdf:application/pdf},
}

@article{painchaud_echocardiography_2022,
	title = {Echocardiography {Segmentation} {With} {Enforced} {Temporal} {Consistency}},
	volume = {41},
	copyright = {All rights reserved},
	issn = {1558-254X},
	doi = {10.1109/TMI.2022.3173669},
	abstract = {Convolutional neural networks (CNN) have demonstrated their ability to segment 2D cardiac ultrasound images. However, despite recent successes according to which the intra-observer variability on end-diastole and end-systole images has been reached, CNNs still struggle to leverage temporal information to provide accurate and temporally consistent segmentation maps across the whole cycle. Such consistency is required to accurately describe the cardiac function, a necessary step in diagnosing many cardiovascular diseases. In this paper, we propose a framework to learn the 2D+time apical long-axis cardiac shape such that the segmented sequences can benefit from temporal and anatomical consistency constraints. Our method is a post-processing that takes as input segmented echocardiographic sequences produced by any state-of-the-art method and processes it in two steps to (i) identify spatio-temporal inconsistencies according to the overall dynamics of the cardiac sequence and (ii) correct the inconsistencies. The identification and correction of cardiac inconsistencies relies on a constrained autoencoder trained to learn a physiologically interpretable embedding of cardiac shapes, where we can both detect and fix anomalies. We tested our framework on 98 full-cycle sequences from the CAMUS dataset, which are available alongside this paper. Our temporal regularization method not only improves the accuracy of the segmentation across the whole sequences, but also enforces temporal and anatomical consistency.},
	number = {10},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Painchaud, Nathan and Duchateau, Nicolas and Bernard, Olivier and Jodoin, Pierre-Marc},
	month = oct,
	year = {2022},
	keywords = {Echocardiography, Image segmentation, CNN, Deep learning, ultrasound, Shape, Magnetic resonance imaging, cardiac segmentation, variational autoencoder, myocardium, left ventricle, Annotations, Cardiac function, Encoding},
	pages = {2867--2878},
	file = {IEEE Xplore Abstract Record:/home/nathan/Zotero/storage/MY6NKT33/figures.html:text/html;IEEE Xplore Full Text PDF:/home/nathan/Zotero/storage/2PNY7NM6/Painchaud et al. - 2022 - Echocardiography Segmentation With Enforced Tempor.pdf:application/pdf},
}

@article{armenta_neural_2023,
	title = {Neural {Teleportation}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2227-7390},
	url = {https://www.mdpi.com/2227-7390/11/2/480},
	doi = {10.3390/math11020480},
	abstract = {In this paper, we explore a process called neural teleportation, a mathematical consequence of applying quiver representation theory to neural networks. Neural teleportation teleports a network to a new position in the weight space and preserves its function. This phenomenon comes directly from the definitions of representation theory applied to neural networks and it turns out to be a very simple operation that has remarkable properties. We shed light on the surprising and counter-intuitive consequences neural teleportation has on the loss landscape. In particular, we show that teleportation can be used to explore loss level curves, that it changes the local loss landscape, sharpens global minima and boosts back-propagated gradients at any moment during the learning process.},
	language = {en},
	number = {2},
	urldate = {2023-01-16},
	journal = {Mathematics},
	author = {Armenta, Marco and Judge, Thierry and Painchaud, Nathan and Skandarani, Youssef and Lemaire, Carl and Gibeau Sanchez, Gabriel and Spino, Philippe and Jodoin, Pierre-Marc},
	month = jan,
	year = {2023},
	keywords = {neural networks, quiver representations, teleportation},
	pages = {480},
	file = {Full Text PDF:/home/nathan/Zotero/storage/LXYV9XUK/Armenta et al. - 2023 - Neural Teleportation.pdf:application/pdf},
}

@inproceedings{ling_extraction_2023,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Extraction of {Volumetric} {Indices} from {Echocardiography}: {Which} {Deep} {Learning} {Solution} for {Clinical} {Use}?},
	copyright = {All rights reserved},
	isbn = {978-3-031-35302-4},
	shorttitle = {Extraction of {Volumetric} {Indices} from {Echocardiography}},
	doi = {10.1007/978-3-031-35302-4_25},
	abstract = {Deep learning-based methods have spearheaded the automatic analysis of echocardiographic images, taking advantage of the publication of multiple open access datasets annotated by experts (CAMUS being one of the largest public databases). However, these models are still considered unreliable by clinicians due to unresolved issues concerning i) the temporal consistency of their predictions, and ii) their ability to generalize across datasets. In this context, we propose a comprehensive comparison between the current best performing methods in medical/echocardiographic image segmentation, with a particular focus on temporal consistency and cross-dataset aspects. We introduce a new private dataset, named CARDINAL, of apical two-chamber and apical four-chamber sequences, with reference segmentation over the full cardiac cycle. We show that the proposed 3D nnU-Net outperforms alternative 2D and recurrent segmentation methods. We also report that the best models trained on CARDINAL, when tested on CAMUS without any fine-tuning, still manage to perform competitively with respect to prior methods. Overall, the experimental results suggest that with sufficient training data, 3D nnU-Net could become the first automated tool to finally meet the standards of an everyday clinical device.},
	language = {en},
	booktitle = {Functional {Imaging} and {Modeling} of the {Heart}},
	author = {Ling, Hang Jung and Painchaud, Nathan and Courand, Pierre-Yves and Jodoin, Pierre-Marc and Garcia, Damien and Bernard, Olivier},
	year = {2023},
	keywords = {CNN, deep learning, Ultrasound, cardiac segmentation, temporal segmentation},
	pages = {245--254},
	file = {Full Text PDF:/home/nathan/Zotero/storage/ZNGCG3NS/Ling et al. - 2023 - Extraction of Volumetric Indices from Echocardiogr.pdf:application/pdf},
}

@article{painchaud_fusing_2025,
	title = {Fusing {Echocardiography} {Images} and {Medical} {Records} for {Continuous} {Patient} {Stratification}},
	volume = {72},
	issn = {1525-8955},
	url = {https://ieeexplore.ieee.org/abstract/document/11131320},
	doi = {10.1109/TUFFC.2025.3600902},
	abstract = {Deep learning enables automatic and robust extraction of cardiac function descriptors from echocardiographic sequences, such as ejection fraction (EF) or strain. These descriptors provide fine-grained information that physicians consider, in conjunction with more global variables from the clinical record, to assess patients’ condition. Drawing on novel Transformer models applied to tabular data, we propose a method that considers all descriptors extracted from medical records and echocardiograms to learn the representation of a cardiovascular pathology with a difficult-to-characterize continuum, namely hypertension. Our method first projects each variable into its own representation space using modality-specific approaches. These standardized representations of multimodal data are then fed to a Transformer encoder, which learns to merge them into a comprehensive representation of the patient through the task of predicting a clinical rating. This stratification task is formulated as an ordinal classification to enforce a pathological continuum in the representation space. We observe the major trends along this continuum on a cohort of 239 hypertensive patients, providing unprecedented details in the description of hypertension’s impact on various cardiac function descriptors. Our analysis shows that: 1) the XTab foundation model’s architecture allows to reach high performance (96.8\% AUROC) even with limited data (less than 200 training samples); 2) stratification across the population is reproducible between trainings [within 5.7\% of mean absolute error (MAE)]; and 3) patterns emerge in descriptors, some of which align with established physiological knowledge about hypertension, while others could pave the way for a more comprehensive understanding of this pathology. The code is available at https://github.com/creatis-myriad/didactic},
	number = {10},
	urldate = {2025-09-30},
	journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
	author = {Painchaud, Nathan and Stym-Popper, Jérémie and Courand, Pierre-Yves and Thome, Nicolas and Jodoin, Pierre-Marc and Duchateau, Nicolas and Bernard, Olivier},
	month = oct,
	year = {2025},
	keywords = {Deep learning, Training, Hypertension, Transformers, Feature extraction, representation learning, Data models, Data mining, Pathology, Medical services, Adaptation models, Cardiac ultrasound, health records, hypertension, multimodal, stratification},
	pages = {1388--1400},
	file = {Full Text PDF:/home/nathan/Zotero/storage/MBI2JNM8/Painchaud et al. - 2025 - Fusing Echocardiography Images and Medical Records for Continuous Patient Stratification.pdf:application/pdf},
}

@inproceedings{painchaud_fusing_2024,
	title = {Fusing {Echocardiography} {Images} and {Medical} {Records} for {Continuous} {Patient} {Stratification}},
	url = {https://openreview.net/forum?id=atsESsgxPa},
	abstract = {Deep learning now enables automatic and robust extraction of cardiac function descriptors from echocardiographic sequences, such as ejection fraction or strain. These descriptors provide fine-grained information that physicians consider, in conjunction with global variables from the clinical record, to assess patients' condition. Drawing on novel transformer models applied to tabular data (e.g. variables from electronic health records), we propose a method that considers descriptors extracted from medical records and echocardiograms to learn a representation of hypertension, a difficult-to-characterize and highly prevalent cardiovascular pathology. Our method first embeds each descriptor separately using modality-specific approaches. These embeddings are fed as tokens to a transformer encoder, which combines them into a unified representation of the patient to predict a clinical rating. This task is formulated as an ordinal classification to enforce a pathological continuum in the representation space. We observe trends along this continuum for a cohort of 239 hypertensive patients to describe the gradual effects of hypertension on cardiac function descriptors. Our analysis shows that i) pretrained weights from a foundation model allow to reach good performance (83\% accuracy) even with limited data (\${\textless}\$ 200 training samples), ii) trends across the population are reproducible between trainings, and iii) for descriptors known to interact with hypertension, patterns are consistent with prior physiological knowledge.},
	language = {en},
	urldate = {2025-11-03},
	author = {Painchaud, Nathan and Courand, Pierre-Yves and Jodoin, Pierre-marc and Duchateau, Nicolas and Bernard, Olivier},
	month = apr,
	year = {2024},
	file = {Full Text PDF:/home/nathan/Zotero/storage/IAEM4LSM/Painchaud et al. - 2024 - Fusing Echocardiography Images and Medical Records for Continuous Patient Stratification.pdf:application/pdf},
}